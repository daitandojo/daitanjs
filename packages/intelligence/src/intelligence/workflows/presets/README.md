This seems not to work. Let us spin this out for two differerent queries. (A) "Does the founder of Bestseller have a pet?" (B) "What is the population of the city on which an Air India plane crashed yesterday? AD (A). The agent needs to define a number of questions. (A1) Who is the founder of Bestseller? => the agent should find this in the RAG. The PDF shows that the founder of bestseller is Troels Holch Povlsen. Time for the next question. The agent should revisit the first question and the information it now knows and formulate the next question (A2). Does Troels Holch Povlsen have a pet? => the agent should find this in the RAG. the txt file says that Troels Holch Povlsen has a cat. So the answer is "Yes, Troels Holch Povlsen (the founder of Bestseller) has a cat.". The agent should give this answer and conclude. Now let us look at question B. The agent should first find more information (by LLM deduction). (B1) Find information on an aircrash yesterday in the news.". It should then use the web tool to scan the news. The query is "Air India Plane Crash yesterday". Scrape the results and their contents and add it to the knowledge base (scratch pad). The LLM should analyse the information presented through question (B2): "Can you find in the information in which city the crash happened?". Based on the scratch pad, the agent finds that the crash happened in Ahmedabad. Now time for the next question: (B3): "what is the population of Ahmedabad, India?". As with EVERY question, first the RAG is scanned. In this case, the answer is not found there. Then as a next step, the LLM scans its own knowledge. The answer is in there: Ahmedabad has 8.5 million inhabitants. This is also the final answer of question B. Let us now brainstorm a little bit. The agent gets a Main question. It breaks this down into sub-questions the answers of which are put on the scratch pad. Then it tries to answer each sub-question, keeping an eye on whether it contributes to the answering of the Main question. For each sub-question, the first source of truth is the scratch pad. Is the answer found in there? Then add it to the scratch pad and if it is the final answer to the main question, respond and exit. Is the answer to the sub-question not in there? Then move to the second layer of ground truth: the RAG. Is the answer found in there? Idem, add it to the scratch pad and if final, respond and exit. Is the answer to the sub-question not in there? Then move to the third layer of ground truth: the LLM's own training knowledge. Is the answer in there? If so, add it to the scratch pad, respond and exit. If the answer to the sub-question is not in there, then resort to the last source of truth: the internet. Formulate search terms for the sub-question and get search results. Assess if either of these search results contains the answer to the sub-question. If so, add it to the scratch pad and move on; if it is the answer to the main question, respond and exit. If the answer to the sub-question is not in the search results, you may (up to three times) repeat the web search with other search terms and try to find the answer.
